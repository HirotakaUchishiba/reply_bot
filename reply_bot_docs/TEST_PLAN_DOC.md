## 第1章：はじめに - 戦略的目標

  
  

### 1.1. 本書の目的

  

本テスト計画書は、「Slack AI Eメールアシスタント」プロジェクトにおける品質保証（QA）活動のすべてを定義、統括、追跡するための唯一の公式文書（Single Source of Truth）である。本書の目的は、場当たり的なテスト活動を排除し、要件定義書 1 および実装設計仕様書 2 に記載されたビジネス目標と技術仕様に基づき、リスク駆動型で体系的な品質検証プロセスを確立することにある。これは、実装設計仕様書で言及されている高レベルな「テスト戦略」を、リソース、スケジュール、成功基準が明確に定義された、管理可能で実行可能な「テスト計画」へと具体化するものである 2。

  

### 1.2. テストの目的と成功基準

  

本テストフェーズの成功は、単にテストケースを完了することではなく、以下のビジネス価値に直結した目的を達成することによって定義される。

- 目的1: ビジネス要件の完全な充足性の検証: 要件定義書で定義されたすべての戦略的ビジネス目標（BG-01〜BG-04）が、システム機能を通じて達成可能であることを実証する 1。
    
- 目的2: 非機能要件（品質特性）の保証: セキュリティ、信頼性、パフォーマンスといった、システムの存続に不可欠な品質特性が、定義された基準（NFR-SEC, NFR-REL, NFR-PERなど）を満たしていることを客観的なデータで証明する 1。
    
- 目的3: 本番リリースに向けたリスクの定量化と受容: テスト活動を通じて特定されたすべての欠陥とリスクを評価し、ビジネスステークホルダーが情報に基づいたリリース判断を下せるよう、残存リスクレベルを明確に報告する。
    

成功基準:

- 計画された全テストケースの実行率が98%以上であること。
    
- クリティカル（Critical）およびメジャー（Major）に分類される未解決の欠陥が0件であること。
    
- 要件定義書の要件追跡マトリクスに記載されたすべての要件が、少なくとも1つのテストケースによってカバーされていること 1。
    
- パフォーマンス要件（NFR-PER-01）である「モーダル表示p95レイテンシ5秒未満」が、負荷テストシナリオ下で達成されること 1。
    
- ユーザー受け入れテスト（UAT）が完了し、主要ユーザーペルソナ「ヒロタカ」を代表する担当者から正式な承認（サインオフ）を得ること 1。
    

---

## 第2章：テストの範囲

  
  

### 2.1. 対象範囲内の機能（In-Scope）

  

本テスト計画は、要件定義書の機能要件（FR-01〜FR-27）で定義された、エンドツーエンドのビジネスワークフロー全体を対象とする 1。具体的には以下の機能群が含まれる。

- メール取り込みと初期処理: AWS SESによるメール受信、Lambdaトリガー、メール本文の解析（FR-01, FR-02, FR-03）。
    
- 状態管理とPIIリダクション: コンテキストID生成、DynamoDBへの状態（pii_mapを含む）永続化、PIIリダクション処理（FR-04, FR-05, FR-06, FR-07）。
    
- Slack通知とインタラクション: Block Kit準拠の通知投稿、アクションボタンの生成（FR-08, FR-09, FR-10, FR-11）。
    
- AIコンテンツ生成: ボタンクリックによるAPI Gateway経由のLambda起動、DynamoDBからの状態復元、OpenAI APIへのプロンプト構築とリクエスト（FR-12, FR-13, FR-14, FR-15, FR-16）。
    
- Human-in-the-Loop（HITL）インターフェース: PIIの再識別化、Slackモーダルの表示、ユーザーによるテキスト編集、モーダル送信（FR-17, FR-18, FR-19, FR-20, FR-21, FR-22）。
    
- メール送信と完了通知: view_submissionイベントの処理、最終メールのSES経由での送信、Slackでの完了確認メッセージ投稿（FR-23, FR-24, FR-25, FR-26）。
    

  

### 2.2. 対象範囲内の品質特性（非機能要件）

  

機能の正常な動作に加え、システムの品質と堅牢性を保証するため、以下の非機能要件の検証を重点的に行う 1。

- セキュリティ（NFR-SEC）: PIIリダクションの精度検証、シークレット管理の構成レビュー、IAMロールの最小権限原則の監査、データ暗- 暗号化設定の確認。
    
- 信頼性（NFR-REL）: データ損失防止メカニズム（DLQ）の意図的な障害テスト、冪等性の検証、DynamoDBへの状態永続化の堅牢性テスト。
    
- パフォーマンス（NFR-PER）: AIドラフト生成を含むモーダル表示までのエンドツーエンドのレイテンシ測定、定義された同時リクエスト数に対するスループットテスト。
    
- コンプライアンス（NFR-COM）: CloudWatch LogsにPIIが記録されていないことの監査、PIIが第三者サービスに送信されないことの検証。
    

  

### 2.3. 対象範囲外（Out-of-Scope）

  

ステークホルダーとの期待値を明確にするため、以下の項目は本テストフェーズの対象外とする 1。

- メール添付ファイルの処理。
    
- 日本語以外の言語サポート。
    
- HTML形式メールのレンダリング。
    
- 100ユーザーを超える大規模な負荷テスト（本フェーズではNFR-PER-02で定義された10同時リクエストをターゲットとする）。
    
- 基盤となるAWSサービス（SES, Lambda, DynamoDB）自体の障害テスト（AWSの責任範囲とする）。
    

---

## 第3章：多層的テスト戦略とアプローチ

  

実装設計仕様書で概説された戦略に基づき、各テストレベルの具体的なアプローチ、責任、およびツールを以下に定義する 2。

  

### 3.1. ユニットテスト (Unit Testing)

  

- 目的: 個々の関数やモジュールが、外部依存から隔離された状態で仕様通りに動作することを検証する。
    
- 責任者: ソフトウェアエンジニア（開発プロセスの一環として実施）。
    
- ツール: pytest（テストフレームワーク）、moto（AWSサービスのモッキング）。
    
- 重点項目:
    

- PIIリダクション・サブシステム: 様々な形式のメールアドレス、電話番号、クレジットカード番号を含むテストデータセットを用いて、リダクション精度とpii_map生成の正確性を検証する。これはセキュリティ要件（NFR-SEC-01）の達成を保証する上で最も重要なユニットテストである 1。
    
- イベントルーター: SES、Slack block_actions、Slack view_submissionの3種類のイベントペイロードを模したモックデータを入力し、正しくロジックが分岐することを検証する。このルーターはシステムの制御フローの要であるため、その網羅的なテストはシステム全体の安定性に不可欠である 2。
    
- プロンプト構築ロジック: 入力されたメール本文と定義済みペルソナから、OpenAI APIコントラクトに準拠したプロンプトが正しく生成されることを検証する 2。
    

  

### 3.2. 結合テスト (Integration Testing)

  

- 目的: 個別のユニットが連携し、AWSサービス間でデータが正しく受け渡されることを検証する。
    
- 責任者: QAエンジニア、ソフトウェアエンジニア。
    
- 環境: staging環境の実際のAWSリソースを使用。
    
- 重点項目:
    

- デュアルイングレス・イベントフロー: 本システムのアーキテクチャは、SESからの非同期イベントとAPI Gatewayからの同期イベントという2つの異なる入口を持つ 2。このテストでは、1. SES -> Lambda -> DynamoDBの非同期フローが正しく状態を永続化できるか、2. API Gateway -> Lambda -> DynamoDBの同期フローが、永続化された状態を正しく読み出せるかを検証する。
    
- 状態管理の完全性: context_idをキーとして、pii_mapを含む完全なワークフローコンテキストがDynamoDBに書き込まれ、後続のLambda実行で欠損なく読み出せることを検証する。pii_mapの損失はワークフローの致命的な失敗に繋がるため、この結合テストは極めて重要である 2。
    
- IAM権限の検証: Lambda実行ロールに付与された権限が、実際に各サービス（DynamoDB, Secrets Manager, SES）へのアクセスに必要十分であることを確認する 2。過剰な権限がないかも監査し、最小権限の原則が遵守されていることを保証する 1。
    

  

### 3.3. エンドツーエンド（E2E）テスト

  

- 目的: ユーザーペルソナ「ヒロタカ」の視点から、実際のビジネスシナリオがシステム全体を通じて期待通りに機能することを検証する 1。
    
- 責任者: QAエンジニア。
    
- アプローチ: 自動化テストスクリプトと手動テストを併用。メール送信クライアントとSlack APIを操作し、システム全体の振る舞いを観測する。
    
- シナリオ例:
    

- 正常系ワークフロー: ユーザーストーリー（US-01〜US-06）に基づき、メール受信から通知、AIドラフト生成、編集、送信、完了確認までの一連の流れをテストする 1。
    
- PII往復検証: PIIを含むメールを送信し、Slack通知ではPIIが表示され、OpenAIへのリクエスト（ログで確認）ではリダクションされ、モーダル表示と最終送信メールでは正しく復元されていることを確認する。
    
- タイムアウト検証: DynamoDBのTTL機能で設定された時間を超えてからSlackのボタンをクリックし、ワークフローが適切に失敗すること（例：エラーメッセージ表示）を確認する。これは、TTLが単なるガベージコレクションではなく、ビジネスルールとして機能することを検証するものである 2。
    

  

### 3.4. ユーザー受け入れテスト (UAT)

  

- 目的: 実際の業務担当者がシステムを操作し、ユーザビリティ（NFR-USA）を含め、ビジネス要件や日常業務のニーズを満たしているか最終確認する 1。
    
- 責任者: プロジェクトマネージャー（主催）、主要ユーザー（実行）。
    
- 参加者: カスタマーサポートチームの代表者数名。
    
- アプローチ: 事前に用意されたテストシナリオ（例：「イベントのキャンセルに関する問い合わせに対応してください」）に基づき、参加者が自由にシステムを操作。フィードバックを収集する。
    

  

### 3.5. 障害・回復性テスト (Failure & Resilience Testing)

  

- 目的: システムが予期せぬ障害に対して、要件通り（NFR-REL）に堅牢に振る舞うことを検証する 1。
    
- 責任者: QAエンジニア、DevOpsエンジニア。
    
- シナリオ例:
    

- DLQ検証: Lambda関数に意図的にエラーを発生させるコードを注入し、デフォルトリトライ後にイベントが設定されたSQSデッドレターキューに正しく転送されることを確認する。これは「データ損失ゼロ」（NFR-REL-01）を保証するための最重要テストである 1。
    
- 外部API障害シミュレーション: OpenAI APIエンドポイントを一時的にブロック、またはモックを用いてエラー応答（例：503 Service Unavailable）を返すように設定し、システムが適切にエラーを処理し、ユーザーにフィードバック（例：「AIの応答が取得できませんでした」）を返すことを確認する。
    

実装設計仕様書で詳述されたオブザーバビリティ・フレームワークは、単なる運用ツールではなく、効果的なテスト、特に非機能要件の検証における前提条件となる 2。本テスト戦略の成功は、構造化ログとカスタムメトリクスを活用し、UIレベルでは不可視なシステムの振る舞いを検証する能力に大きく依存する。例えば、「PIIがOpenAIに送信されないこと（NFR-SEC-01）」や「PIIがログに記録されないこと（NFR-COM-01）」をどのように検証するかという問いに対する答えは、UIには存在しない 1。唯一の検証手段は、実装設計書が要求する構造化ログと相関IDを利用することである 2。したがって、PIIに関するE2Eテスト手順には、(a)ワークフローをトリガーし、(b)初期ログから相関IDを捕捉し、(c)CloudWatch Logs Insightsを用いてその相関IDを持つ全ログを照会し、(d)ログエントリ内にPIIが存在しないこと、特にOpenAI APIコール用に記録されたペイロードにリダクション済みプレースホルダーが含まれていることをアサーションする、というステップが不可欠となる。これは、テスト計画の開始基準に「オブザーバビリティ・フレームワークが

staging環境で完全に実装・検証済みであること」を追加する必要があることを意味する。このフレームワークなしでは、重要なセキュリティおよびコンプライアンス要件を検証する能力が著しく損なわれ、テストはブラックボックス化してしまう。かくして、オブザーバビリティ・フレームワークは「運用チームのための便利機能」から「品質保証チームのための必須ツール」へとその役割を変えるのである。

---

## 第4章：テスト環境とデータ管理

  
  

### 4.1. テスト環境構成

  

- 環境: テストは、本番環境（prod）からAWSアカウントレベルで分離されたstaging環境で実施する 2。
    
- プロビジョニング: staging環境のすべてのインフラは、Terraform Workspacesを用いてコード（IaC）として管理され、本番環境との一貫性を保証する 2。
    
- 外部サービス:
    

- Slack: 専用のテスト用Slackワークスペースを使用する。
    
- OpenAI: 開発用のAPIキーを使用し、本番環境とは異なる予算管理下に置く。
    

- データストア: staging環境専用のDynamoDBテーブル、SQSキューを使用する。テスト実行前には、テーブルをクリーンな状態にリセットする手順を確立する。
    

  

### 4.2. テストデータ戦略

  

- 目的: 現実的で多様なシナリオを網羅し、再現可能なテストを実行するためのデータセットを準備・管理する。
    
- データコーパス:
    

- Eメールデータ: 少なくとも50件のユニークなテストEメールを作成する。これには、一般的な問い合わせ、肯定的なフィードバック、否定的なフィードバック、複数のPII（メール、電話番号、住所など）を含むメール、長文メール、空の本文を持つメールなど、様々なバリエーションを含める。
    
- PIIデータセット: PIIリダクション・サブシステムの精度を測定するため、一般的な形式から稀な形式まで、多様なパターンの個人情報リストを準備する。
    

- データ生成とマスキング: テストデータに実在の個人情報が含まれないよう、すべてのデータは合成的に生成されるか、厳格なマスキング処理を施す。
    
- テストアカウント: メール送受信のためのテスト用メールアカウントを複数準備する。
    

---

## 第5章：ガバナンスと実行フレームワーク

  
  

### 5.1. テスト開始・終了基準 (Entry/Exit Criteria)

  

- 開始基準 (Entry Criteria):
    

- 本テスト計画書がすべての主要ステークホルダーによってレビューされ、承認されていること。
    
- 対象となる機能のコードがstaging環境にデプロイされ、基本的なスモークテストが成功していること。
    
- CI/CDパイプラインにおけるすべてのユニットテストがパスしていること 2。
    
- テストに必要な環境、データ、ツールがすべて準備完了していること。
    

- 終了基準 (Exit Criteria):
    

- 本計画書のセクション1.2で定義された成功基準がすべて満たされていること。
    
- すべてのテストケースが実行され、その結果がテスト管理ツールに記録されていること。
    
- すべての重大な欠陥が修正され、その修正が検証されていること。
    
- 最終テストサマリーレポートが作成され、ステークホルダーに提出されていること。
    

  

### 5.2. 欠陥管理プロセス

  

- ツール: Jira（または同等のバグ追跡システム）を使用する。
    
- ライフサイクル: 発見 -> 新規 -> 担当者割当 -> 対応中 -> 修正済み -> 検証 -> クローズ/再オープン
    
- 優先度定義:
    

- P1 (Critical): システムの主要なワークフローを完全にブロックする、データ損失やセキュリティ脆弱性を引き起こす問題。即時対応が必要。
    
- P2 (Major): 主要な機能が利用できない、または非機能要件を著しく満たさないが、回避策が存在する問題。
    
- P3 (Minor): UIの不具合や軽微な機能不全など、ユーザー体験を損なうが、主要なワークフローは完了できる問題。
    
- P4 (Trivial): タイプミスや表示のズレなど、機能に影響を与えない問題。
    

- トリアージ会議: 毎日、QA、開発、PMの代表者で短い会議を開き、新規に報告された欠陥の優先度付けと担当者割り当てを行う。
    

  

### 5.3. テスト成果物 (Deliverables)

  

- テスト計画書（本書）
    
- テスト仕様書（テストケース群）
    
- 欠陥レポート（Jira上のチケット）
    
- テスト実行ログおよびエビデンス
    
- 最終テストサマリーレポート（実行結果、品質評価、残存リスクの要約）
    

---

## 第6章：体制と計画

  
  

### 6.1. 役割と責任

  

テストプロセスにおける各活動に対して「誰が実行責任者（Responsible）か」「誰が説明責任者（Accountable）か」「誰が協業相手（Consulted）か」「誰が情報提供先（Informed）か」を明確に定義することは、タスクの重複や抜け漏れを防ぎ、円滑なコミュニケーションを促進する上で不可欠である。テスト活動には開発者、QA、PM、ユーザーなど複数の役割が関わるため、役割の曖昧さは「誰かがやるだろう」という思い込みからタスクが放置されるリスクを生む。RACIマトリクスは、この曖昧さを排除するための業界標準フレームワークであり、本計画書を単なる技術的な手順書から、実行可能なプロジェクト管理ツールへと昇華させる 3。

|   |   |   |   |   |   |
|---|---|---|---|---|---|
|活動|プロジェクトマネージャー|QAリード|QAエンジニア|開発リード|ソフトウェアエンジニア|
|テスト計画書の作成・承認|A|R|I|C|I|
|ユニットテストの設計・実行|I|I|I|A|R|
|結合・E2Eテストの設計・実行|I|A|R|C|C|
|欠陥の報告|I|A|R|I|R|
|欠陥の修正|I|C|I|A|R|
|ユーザー受け入れテストの主催|A|C|C|I|I|
|最終リリース判断|A|C|I|C|I|

(A: Accountable, R: Responsible, C: Consulted, I: Informed)

  

### 6.2. スケジュールとマイルストーン

  

以下にテスト活動の暫定的なスケジュールと主要なマイルストーンを示す。具体的な日付はプロジェクト全体の計画と同期して決定される。

- テスト計画・設計フェーズ: YYYY/MM/DD - YYYY/MM/DD
    
- テスト環境構築・データ準備: YYYY/MM/DD - YYYY/MM/DD
    
- ユニット/結合テスト実行: YYYY/MM/DD - YYYY/MM/DD (開発スプリントと並行)
    
- E2Eテスト実行サイクル1: YYYY/MM/DD - YYYY/MM/DD
    
- E2Eテスト実行サイクル2: YYYY/MM/DD - YYYY/MM/DD
    
- UAT実行: YYYY/MM/DD - YYYY/MM/DD
    
- 最終リグレッションテスト: YYYY/MM/DD - YYYY/MM/DD
    
- テスト完了・レポート提出: YYYY/MM/DD
    

  

### 6.3. リスクと対策

  

プロジェクトのリスクはテスト活動そのものにも存在する。潜在的な問題を事前に特定し、プロアクティブな対策を計画することで、テストスケジュールの遅延や品質低下を防ぐ。このリスク管理は、本テスト計画書が担うべき戦略的機能の核心部分である 3。リアクティブな問題対処はプロジェクトの遅延に直結するため、リスクを「特定」「評価」「対策計画」のステップで管理する構造化されたアプローチを採用する。

|   |   |   |   |   |
|---|---|---|---|---|
|リスクID|リスク内容|発生確率|影響度|対策計画|
|RISK-QA-01|staging環境の不安定性によるテスト中断|中|大|DevOpsチームと連携し、環境のヘルスチェックを自動化。主要なテストサイクル開始前に安定化期間を設ける。|
|RISK-QA-02|OpenAI APIのレートリミット超過や性能劣化によるテストの遅延・失敗|中|中|OpenAI APIへのコールをモックするテストを優先的に実施。E2Eテストは、API負荷が低い時間帯にスケジュールする。APIコール数を監視し、異常な増加がないか確認する。|
|RISK-QA-03|テストデータの不足や不備により、特定シナリオ（特にPII関連）の網羅性が低下する|高|大|テストデータ戦略（4.2）に基づき、テスト設計フェーズの早い段階でデータコーパスの作成に着手する。ピアレビューを通じてデータの多様性を確保する。|
|RISK-QA-04|SlackまたはOpenAIの仕様変更により、結合部分がテスト期間中に破壊される|低|大|外部サービスのAPIバージョンを固定する。主要なAPIエンドポイントに対する定期的なヘルスチェック（契約テスト）をCIパイプラインに組み込むことを検討する。|
|RISK-QA-05|開発スケジュール遅延により、十分なテスト期間が確保できない|中|大|プロジェクトマネージャーと定期的に進捗を確認し、リスクを早期に共有。リスクベースドテスティングアプローチを採用し、万が一期間が短縮された場合でも最重要機能のテストが完了するよう優先順位を明確にしておく。|

---

## 第7章：付録

  
  

### 7.1. 要件追跡マトリクス (Requirements Traceability Matrix - RTM)

  

本マトリクスは、プロジェクトの「なぜ（ビジネス目標）」と「何を（要件）」を、「どのように検証したか（テストレベル/ケース）」に直接結びつける、監査可能な証跡を提供する。これにより、すべてのテスト活動がビジネス価値に貢献していることを保証し、要件のテストカバレッジが100%であることをステークホルダーに証明する。要件定義書で提案された概念を、本テスト計画の文脈で完成させるものである 1。各要件IDが、それを検証する具体的なテストケースIDにマッピングされることで、「このビジネス目標は、この機能要件によって実現され、その機能要件は、このE2Eテストケースによって検証済みです」という一貫したストーリーラインを誰でも追跡できるようになり、プロジェクト品質の究極的な証明となる。

|   |   |   |   |   |   |
|---|---|---|---|---|---|
|要件ID|要件概要|ユニットテストケースID|結合テストケースID|E2EテストケースID|UATシナリオID|
|BG-01, BG-02|効率性・生産性の向上|||||
|US-03|ワンクリックでAI返信ドラフトを生成|-|-|E2E-AI-GEN-01|UAT-SCN-01|
|FR-15|構造化プロンプトを構築|UNIT-PROMPT-01|-|-|-|
|NFR-PER-01|モーダル表示p95 < 5秒|-|-|E2E-PERF-01|UAT-SCN-01|
|BG-03|品質の改善|||||
|US-04|AIドラフトをレビュー・編集|-|-|E2E-MODAL-EDIT-01|UAT-SCN-02|
|FR-21|ユーザーによるテキスト変更|-|INT-MODAL-SUBMIT-01|E2E-MODAL-EDIT-01|UAT-SCN-02|
|すべて|横断的要件|||||
|FR-04|PIIリダクション処理|UNIT-PII-001, 002|-|E2E-PII-001|UAT-SCN-03|
|NFR-SEC-01|PIIリダクション精度99.9%|UNIT-PII-ACC-01|-|-|-|
|NFR-REL-01|データ損失ゼロ|-|INT-DLQ-FAIL-01|E2E-FAIL-001|-|

#### 引用文献

1. 要件定義書
    
2. 実装設計仕様書
    
3. 開発資料の網羅性と不足資料の提案
    

**